{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383ab587-6257-49d5-960a-8894965d3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "from dwave.embedding import verify_embedding\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite, TilingComposite,FixedEmbeddingComposite\n",
    "from dwave.samplers import SimulatedAnnealingSampler \n",
    "from dimod.serialization.format import Formatter\n",
    "from datetime import datetime\n",
    "from dwave_networkx import pegasus_graph\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from minorminer import find_embedding, layout, busclique\n",
    "import networkx as nx\n",
    "from numpy import kron\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import eig\n",
    "from dwave.cloud import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8ac998-bf1c-4b88-87f7-e4d19f869656",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplingsPth = \"C:/Users/cicer/Documents/ThesisWork/Ocean/Couplings\"\n",
    "hamiltoniansPth = \"C:/Users/cicer/Documents/ThesisWork/Ocean/Hamiltonians\"\n",
    "notebookOutputsPth = \"C:/Users/cicer/Documents/ThesisWork/Ocean/NotebookOutputs\"\n",
    "schedPath = \"C:/Users/cicer/Documents/ThesisWork/Ocean/AnnealingSchedules\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abc80041-1583-4bff-bd4e-483e2e423be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnAB(s):\n",
    "    \"\"\"\n",
    "    Given a value for s, return the corresponding A and B value from the annealing schedule\n",
    "    precision of s is limited to scale of 1e-3\n",
    "    \"\"\"\n",
    "    ind = np.where(A[:,0]==s)\n",
    "    return [A[ind][0][1],B[ind][0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c480cd97-86e9-49ee-ab3a-c261524579fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def1DCouplings(L):\n",
    "    \"\"\"\n",
    "    Method for defining nearest neighbours couplings of a line of L qubits randomly assigning\n",
    "    the couplings a +/- 1 or random output based on a Gaussian spread. Does not have PBC\n",
    "\n",
    "    Outputs:\n",
    "    [J_dict, J_matrix]\n",
    "    J_dict: Formatted dictionary of couplings to be used in dwave's Sampler.sample_ising() functions\n",
    "    J_matrix: Coupling matrix output to be used later for lowest energy state calculations using the findLowest(L,J) function\n",
    "    \"\"\"\n",
    "\n",
    "    J_matrix = []\n",
    "    J_dict = {}\n",
    "    for i in range(L-1):\n",
    "        # j_i = random.randrange(-1,2,2)\n",
    "        j_i = random.uniform(-1,1)\n",
    "        row = np.zeros(shape = L)\n",
    "        row[i+1] = 1\n",
    "        # print(row)\n",
    "        J_matrix.append(row)\n",
    "        key = (i,i+1)\n",
    "        J_dict.update({key:j_i})\n",
    "    \n",
    "    J_matrix.append(np.zeros(shape=L))\n",
    "\n",
    "    \n",
    "    return J_dict, np.array(J_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b53f978-4be1-4744-9c87-98ae06e54d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defCouplings(L, PBC):\n",
    "    \"\"\"\n",
    "    Method for finding nearest neighbours couplings of an LxL lattice \n",
    "    and randomly assigning the couplings a +1 or -1 value\n",
    "\n",
    "    Args:\n",
    "    L: Side length of the system, system is defined as an LxL system\n",
    "    PBC: Indicate whether to include periodic boundary conditions or not, currently does nothing\n",
    "    \n",
    "    Outputs:\n",
    "    [J_dict, J_matrix]\n",
    "    J_dict: Formatted dictionary of couplings to be used in dwave's Sampler.sample_ising() functions\n",
    "    J_matrix: Coupling matrix output to be used later for lowest energy state calculations using the findLowest(L,J) function\n",
    "    \"\"\"\n",
    "    J_matrix = []\n",
    "    J_dict = {}\n",
    "    for i in range(L*L):\n",
    "        row = np.zeros(shape = L*L)\n",
    "        \n",
    "        if(i <L*(L-1)): # Add coupling to South neighbour\n",
    "            try:\n",
    "                row[i+L] = 1\n",
    "            except IndexError:\n",
    "                pass\n",
    "        if(i%L!=(L-1)): # Add coupling to East neighbour, unless east-edge site\n",
    "            row[i+1] = 1\n",
    "        if(i%L==0): # Add coupling to \"West\" neighbour for west-edge sites\n",
    "            row[i+L-1] = 1\n",
    "        if(i<L):\n",
    "            row[i+L*(L-1)] = 1\n",
    "        # print(row)\n",
    "        J_matrix.append(row)\n",
    "    J_matrix = np.array(J_matrix)\n",
    "    # By default only creates an upper triangular matrix, if working with QUBOs leave as is, if working in Ising model use a square matrix\n",
    "    # J_matrix = J_matrix + J_matrix.T\n",
    "    ij = np.where(J_matrix == 1)\n",
    "    coupls = tuple(zip(*ij))\n",
    "\n",
    "    for i in coupls:\n",
    "        # j_i = random.randrange(-1,2,2)\n",
    "        j_i = random.uniform(-1,1)\n",
    "        # j_i = 1\n",
    "        J_dict.update({i:j_i})\n",
    "        J_matrix[i[0]][i[1]] = j_i         \n",
    "    \n",
    "    return J_dict, J_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "419f6c66-e048-4169-9fe9-4f1dfcc6012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLowest(L, J):\n",
    "    \"\"\"\n",
    "    Find lowest energy of a spin configuration given some coupling matrix\n",
    "\n",
    "    Args:\n",
    "    L: Length and Width of 2-D square Ising model (i.e. 3x3 model, L=3)\n",
    "    J: Coupling matrix\n",
    "\n",
    "    Outputs: [minEnergy, minState, degenerateStates]\n",
    "    minEnergy: Energy of minimum energy state\n",
    "    array minState: Integer number representing state configuration of minimum energy state\n",
    "    array degenerateStates: Integer number(s) representing degenerate ground state configurations\n",
    "    \"\"\"\n",
    "    # Add back J\n",
    "    numSpins = L*L\n",
    "    numStates = 2**numSpins\n",
    "    minState = None\n",
    "    minEnergy = 10**10\n",
    "    degenerateStates = []\n",
    "    \n",
    "    for i in range(numStates):\n",
    "        s = numToState(i, numSpins)\n",
    "                \n",
    "        # Calculate energy of state \n",
    "        currEnergy = np.dot(s, np.dot(J,s))\n",
    "\n",
    "        # Switch if necessary, raise degenerate ground state flag if applicable\n",
    "        if(currEnergy < minEnergy):\n",
    "            minEnergy = currEnergy\n",
    "            # minState = s.copy()\n",
    "            minState = i\n",
    "            degenerateStates = [] # If a new lower state is found, formerly degenerate ground states just become degenerate states and are no longer of interest\n",
    "        elif (abs(currEnergy - minEnergy) < 1e-10 ):\n",
    "            degenerateStates.append(i)\n",
    "\n",
    "    # degenerateStates = np.insert(degenerateStates, 0, minState, axis=0)\n",
    "\n",
    "    return minEnergy, minState, degenerateStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd9f8947-4baa-4f7f-9339-ffecb3d94cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numToState(i, numSpins):\n",
    "    \"\"\"\n",
    "    Given a number and the number of states for a spin configuration convert the number to a binary number then a spin configuration with 1 -> +1 and 0 -> -1 spins\n",
    "\n",
    "    Args:\n",
    "    i: Number to convert\n",
    "    numStates: Number of states to look at\n",
    "\n",
    "    Output:\n",
    "    s: Spin Configuration as an array with each spin a separate index\n",
    "    \"\"\"\n",
    "    s = np.zeros(numSpins, dtype=int)\n",
    "\n",
    "    for j in range(numSpins):\n",
    "        if( (i & (1 << j)) != 0):\n",
    "            s[j] = 1\n",
    "        else:\n",
    "            s[j] = -1\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9afc4e8-2b29-4acd-b195-4526e937c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToArr(statesDict):\n",
    "    \"\"\"\n",
    "    Given a dictionary of site values, with the site index and site value, convert it to an array\n",
    "\n",
    "    Args:\n",
    "    dict: Dictionary of sites to convert to array\n",
    "\n",
    "    Output:\n",
    "    arr - Array of site values\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    for i in statesDict:\n",
    "        arr.append(statesDict[i])\n",
    "\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "170c2cf4-79e2-4935-afd1-d401b3ccb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(stateArr, degenStates):\n",
    "    \"\"\"\n",
    "    Given a state returned from DWave sampler, and degenerate ground states found check that the state array is found among the degenerate states\n",
    "\n",
    "    Args:\n",
    "    stateArr: state returned from the DWave sampler\n",
    "    degenStates: degenerate states found by the findLowest() method\n",
    "\n",
    "    Output:\n",
    "    None - prints out if the state is found\n",
    "    \"\"\"\n",
    "    L = len(stateArr)\n",
    "    for i in range(len(degenStates)):\n",
    "        print(stateArr)\n",
    "        print(degenStates[i])\n",
    "        print(L)\n",
    "        temp = np.all(stateArr == numToState(degenStates[i],L*L))\n",
    "        if(temp):\n",
    "            print(\"Passed; index  \" +str(i) + \"of groundStates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "18a010a9-6552-4a05-a7e8-4b9f6fddff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJ(J_dict,L, dims):\n",
    "    \"\"\"\n",
    "    Given a coupling dictionary, one length measurement of the system, and the number of \n",
    "    dimensions in the system (1 or 2), save a file using these couplings in such a way\n",
    "    that they can be submitted to the McGroundstate server provided by University of Bonn\n",
    "\n",
    "    Args:\n",
    "    J_dict: Dictionary of all the couplings defined by DWaves standards to be submitted to their Leap service\n",
    "    L: Length of one side of the system: for 1-D system the length of the system; for 2-D system, the length of one side\n",
    "    dims: Number of dimensions of the system: 1-D: dims = 1; 2-D: dims = 2.\n",
    "\n",
    "    Output:\n",
    "    filename: Filename the file was saved to without the extension \n",
    "    \"\"\"\n",
    "    \n",
    "    shape = 'u'\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H\\'%M\\'%S\")\n",
    "    filename = f\"{couplingsPth}/Couplings_L={L}_{shape}_{timestamp}.sg\"\n",
    "    nspins = L**dims\n",
    "    ninter = len(J_dict)\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(f\"# {filename[52:-3]}\\n\")\n",
    "        file.write(f\"{nspins} {ninter}\\n\")\n",
    "        for (i,j), Jij in J_dict.items():\n",
    "            if Jij < 0:\n",
    "                file.write(f\"{i+1} {j+1} {-Jij:0.5f}\\n\")\n",
    "            else:\n",
    "                file.write(f\"{i+1} {j+1} {-Jij:0.5f}\\n\")\n",
    "\n",
    "    print(f\"Couplings saved at: {filename}\")\n",
    "    return filename[62:-3] # Return run's unique identifier string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac5caeea-8616-416b-9731-b1164718a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleSpinTerm(N, s, pauli, c=1.0):\n",
    "    \"\"\"\n",
    "    Function for calculating the contribution to the Hamiltonian from a single spin, used to reduce this calculation to one line in other code\n",
    "\n",
    "    Args:\n",
    "        N (int) - Number of spins in state\n",
    "        s (int) - spin index for which the contribution comes from\n",
    "        pauli (nd.array) - Pauli matrix that will be used in calculations, will be either Pauli-x or Pauli-y matrix in this case\n",
    "        c (float, optional) - Constant to multiply term by\n",
    "\n",
    "    Return:\n",
    "        nd.array - Contribution to Hamiltonian matrix from the particular spin\n",
    "    \"\"\"\n",
    "    sigma = 1.0\n",
    "    for j in range(N):\n",
    "        if j == s: # When reached qubit index, work with Pauli_x matrix\n",
    "            if j != 0: #  \n",
    "                sigma = np.kron(sigma, pauli) \n",
    "            else :\n",
    "                sigma = pauli\n",
    "        else: # Otherwise work with identity matrix\n",
    "            if j != 0:\n",
    "                sigma = np.kron(sigma, I) \n",
    "            else:\n",
    "                sigma = I\n",
    "\n",
    "    return c*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00f8bfe3-ba1b-4e56-b731-3e7293394b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coupledSpinsTerm(N, s1, s2, J_12=1.0):\n",
    "    \"\"\"\n",
    "    Function for calculating the contribution to the Hamiltonian from a single spin, used to reduce this calculation to one line in other code\n",
    "\n",
    "    Args:\n",
    "        N (int) - Number of spins in state\n",
    "        s1 (int) - spin index of one coupled spin\n",
    "        s2 (int) - spin index of second coupled spin\n",
    "        c (float, optional) - Constant to multiply term by\n",
    "\n",
    "    Return:\n",
    "        nd.array - Contribution to Hamiltonian matrix from the particular spin\n",
    "    \"\"\"\n",
    "    p_z = np.array([[1,0],[0,-1]])\n",
    "    I = np.array([[1,0],[0,1]])\n",
    "    sigma = 1.0\n",
    "    for j in range(N):\n",
    "        if j == s1 or j == s2: # When reached qubit index, work with Pauli_x matrix\n",
    "            if j != 0: #  \n",
    "                sigma = np.kron(sigma, p_z) \n",
    "                # print(\"Took tensor product with pauli matrix\")\n",
    "            else :\n",
    "                sigma = p_z\n",
    "        else: # Otherwise work with identity matrix\n",
    "            if j != 0:\n",
    "                sigma = np.kron(sigma, I) \n",
    "                # print(\"Took tensor product with identity matrix\")\n",
    "            else:\n",
    "                sigma = I\n",
    "        # print(sigma)\n",
    "\n",
    "    return J_12*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6fbb0b63-933d-4543-b21f-759f386a4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defHamiltonian(A, B, J_matrix):\n",
    "    \"\"\"\n",
    "    Define Hamiltonian given the A(s) and B(s) values paused at along with the coupling matrix\n",
    "\n",
    "    A (float): Strength of transverse field taken from the annealing schedule excel sheet provided by DWave\n",
    "\n",
    "    B (float): Strength of classical problem Hamiltonian also taken from annealing schedule excel sheet provided by DWave\n",
    "\n",
    "    J_matrix (nd.array): 2 dimensional Numpy array of spin interaction couplings\n",
    "    \"\"\"\n",
    "    shape = 'u'\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H\\'%M\\'%S\")\n",
    "    filename = f\"{hamiltoniansPth}/Hamiltonian_L={L}_{shape}_{timestamp}.csv\"\n",
    "    n = len(J_matrix)    \n",
    "    # N = int(np.log2(n))\n",
    "    \n",
    "    # Calculate transverse field term\n",
    "    Hdim = 2**n\n",
    "    datatype = np.float16\n",
    "    H_trans = np.zeros((Hdim, Hdim), dtype = datatype)\n",
    "    H_coup = np.zeros((Hdim, Hdim), dtype = datatype)\n",
    "    H = np.zeros((Hdim, Hdim), dtype = datatype)\n",
    "\n",
    "    print(f\"Defining {Hdim}x{Hdim} (2**{n}x2**{n}) Hamiltonian\")\n",
    "    \n",
    "    # Adding the x-spin contributions from each qubit\n",
    "    for s in range(n):\n",
    "        # Calculate contribution and add to Hamiltonian\n",
    "        contribution = singleSpinTerm(n, s, p_x, A)\n",
    "        H_trans -= contribution\n",
    "\n",
    "    # Adding the coupled spins\n",
    "    for i in range(len(J_matrix)):\n",
    "        for j in range(len(J_matrix[0])):\n",
    "            if(J_matrix[i][j] != 0):\n",
    "                contribution = coupledSpinsTerm(n, i, j, J_matrix[i][j])\n",
    "            H_coup -= B*contribution\n",
    "\n",
    "    # Contributions due to linear biasing is forgon as \n",
    "    # for now there is no need but should the need arise \n",
    "    # in the future the proper amendments can be made \n",
    "\n",
    "    H = H_trans + H_coup\n",
    "\n",
    "    np.savetxt(filename, H, fmt='%.6f', delimiter=',', header=filename[27:-3])\n",
    "    print(f\"Hamiltonian saved at {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7485d0bb-2f25-4c77-9d84-4811173df390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnServerCoupls(J_coupls):\n",
    "    \"\"\"\n",
    "    Originally designed to work together with the saveJ() function to conveniently\n",
    "    save couplings in a way the validation server could work with them but no longer needed\n",
    "\n",
    "    Args:\n",
    "    J_coupls: Input dictionary containing couplings of system\n",
    "\n",
    "    Outputs:\n",
    "    srv_coupls: Same input dictionary with keys incremented so indices start from 1, not 0\n",
    "    \"\"\"\n",
    "    \n",
    "    srv_coupls = {}\n",
    "\n",
    "    for i in J_coupls.keys():\n",
    "        key = (i[0]+1,i[1]+1)\n",
    "        # print(key)\n",
    "        srv_coupls[key] = J_coupls[i]\n",
    "        \n",
    "    return srv_coupls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30a17363-fa1f-4209-bc2a-29df587ba9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipRand(state):\n",
    "    \"\"\"\n",
    "    Given a state return the state with randomly flipped states.\n",
    "    Used to get a random starting state for reverse annealing after finding\n",
    "    the ground state in a forward annealing run.\n",
    "\n",
    "    Args:\n",
    "    state: Ground state array of current system\n",
    "\n",
    "    Output:\n",
    "    state: State of semi random bits for qubit\n",
    "    \"\"\"\n",
    "    for i in state.keys():\n",
    "        state[i] *= (-1)**i\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d94be46-cbaa-4f15-95f3-f734f77a52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeEndpoint(tf, maxSlope, sp, epsilon = 1e3):\n",
    "    \"\"\"\n",
    "    Find last possible time before starting final 'quench' annealing step, to\n",
    "    minimize time spent by the system moving out of the state of interest. The\n",
    "    slope cannot be larger so this iterative method gets as close as possible\n",
    "    within tolerance\n",
    "\n",
    "    Args:\n",
    "    tf: Final time, the total elapsed time of the annealing schedule in microseconds\n",
    "    maxSlope: Maximum rate of change of s wrt t (ds/dt), defined as the inverse of the \n",
    "              minimum annealing time of the sampler, defined by the sampler\n",
    "    sp: Pause point of annealing progress\n",
    "    epsilon: Tolerance for how close the found value should be to the max value\n",
    "\n",
    "    Output:\n",
    "    tp_end: Time to define end of pause period, maximizing change of s\n",
    "    \"\"\"\n",
    "    tp_end = None\n",
    "    checkSlope = True\n",
    "    \n",
    "    while(checkSlope):\n",
    "        tp_end = tf+(sp-1.0)/maxSlope\n",
    "        slope = (1.0-sp)/(tf-tp_end)\n",
    "        diff = maxSlope-slope\n",
    "        if(abs(diff) < epsilon):\n",
    "            checkSlope=False\n",
    "        else:\n",
    "            tp_end += (diff/abs(diff))*0.01\n",
    "    \n",
    "    return tp_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "24b863e5-d103-4241-8447-881436ea699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recToArrs(record):\n",
    "    energy_occurrences = defaultdict(int)\n",
    "\n",
    "    for _, energy, occurrences, _ in record:\n",
    "        energy_occurrences[energy] += occurrences\n",
    "    \n",
    "    energies = []\n",
    "    occurrences = []\n",
    "    for energy, occurrence in sorted(energy_occurrences.items()):\n",
    "        energies.append(energy)\n",
    "        occurrences.append(occurrence)\n",
    "\n",
    "    return [values, occurrences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2566ce9b-a7c6-420c-880a-92243ea4acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc3(i):\n",
    "    return m.trunc(i*1000)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3c2741d-8c8e-4e93-a510-dc7b68db5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BITVAL(i,a):\n",
    "    return int(bool(i&1<<a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9eb24d3b-6574-4ef5-92e5-49125d529260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BITFLIP(i,a):\n",
    "    return i^1<<a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6480339-bfe9-4423-9b06-a986071b47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hv(x, J, s):\n",
    "    print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206481d-ef21-42bd-ac14-171cb8b7f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining matrices to use\n",
    "x = 1/2*np.array([[0,1],\n",
    "                   [1,0]])\n",
    "z = 1/2*np.array([[1,0],\n",
    "                   [0,-1]])\n",
    "y = 1/2*np.array([[0, 1.j],\n",
    "                   [-1.j, 0]], dtype=np.complex_)\n",
    "I = np.array([[1,0],\n",
    "              [0,1]])\n",
    "\n",
    "# Getting A(s) and B(s) values in the program\n",
    "test = pd.read_excel(\"09-1263A-B_Advantage_system4_1_annealing_schedule.xlsx\", 1,\n",
    "                     usecols = \"A:C\", \n",
    "                     names = [\"s\",\"A\",\"B\"],\n",
    "                     )\n",
    "A = test[[\"s\",\"A\"]].to_numpy()\n",
    "A = {trunc3(row[0]): row[1] for row in A}\n",
    "B = test[[\"s\",\"B\"]].to_numpy()\n",
    "B = {trunc3(row[0]): row[1] for row in B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def2d12-4ad2-40e0-90cb-f55a95b65443",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = np.array(\n",
    "    [[0, 1, 8],\n",
    "     [0, 0, 4],\n",
    "     [0, 0, 0]])\n",
    "s = 0.3\n",
    "px0 = kron(kron(x,I),I)\n",
    "px1 = kron(kron(I,x),I)\n",
    "px2 = kron(kron(I,I),x)\n",
    "driver = (px0+px1+px2)\n",
    "# driver = -A[s]*0.5*(px0+px1+px2)\n",
    "pz01 = J[0][1]*kron(kron(z,z),I) #J_0,1\n",
    "pz12 = J[1][2]*kron(kron(I,z),z) #J_1,2\n",
    "pz20 = J[0][2]*kron(kron(z,I),z) #J_2,0\n",
    "problem = (pz01 + pz12 + pz20)\n",
    "# problem = B[s]*0.5*(pz01 + pz12 + pz20)\n",
    "H_ref = driver + problem54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68748c8-6b35-49bb-8d74-59c7e6345821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57e065-cce7-4ec1-99c4-361257099091",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.3\n",
    "test = JtoH(J,s, midAnneal = 0)\n",
    "# print(test)\n",
    "values, vectors = eig(test)\n",
    "print(values)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b71e5dea-85c9-4811-9d69-e790feeca821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JtoH(J,s, midAnneal=1):\n",
    "    n = len(J)\n",
    "    L = 2**n\n",
    "    H = np.zeros((L,L))\n",
    "\n",
    "    for i in range(L):\n",
    "        const = 0\n",
    "        for a in range(n):\n",
    "            b = (a+1)%n\n",
    "            bitsum = BITVAL(i,a)+BITVAL(i,b)\n",
    "            const += ((-1)**bitsum)*J[min(a,b),max(a,b)]\n",
    "        if midAnneal:\n",
    "            H[i][i] = const*B[s]/2\n",
    "        else:\n",
    "            H[i][i] = const\n",
    "\n",
    "    for i in range(L):\n",
    "        for a in range(n):\n",
    "            k = BITFLIP(i,a)\n",
    "            if midAnneal:\n",
    "                H[i][k] = -1*A[s]/2\n",
    "            else:\n",
    "                H[i][k] = -1\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de3b59-b7df-405a-b831-f22acd0c0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problem*4)\n",
    "# values,vectors = eig(H_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee24e0-c8c9-492c-9b09-a825b01bffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1f73e-484f-4eaa-b882-f082c0b7e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(J_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11956f46-d7b2-464b-8791-b1fc323c9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JtoH("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8870a-61d2-4896-a24a-f6f8f7cfac85",
   "metadata": {},
   "source": [
    "**-------------------------------------------------- End of helper function definitions ----------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fd5d0-2bb8-46ee-9da2-be71ff572888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler = DWaveSampler()\n",
    "# samplerEC = EmbeddingComposite(sampler)\n",
    "\n",
    "# # print(qpu.properties[\"annealing_time_range\"])\n",
    "# print(\"Maximum anneal-schedule points: {}\".format(sampler.properties[\"max_anneal_schedule_points\"]))\n",
    "# print(\"Annealing time range: {}\".format(sampler.properties[\"annealing_time_range\"]))\n",
    "# print(\"Connected to sampler:\", sampler.solver.name)\n",
    "# min_anneal = sampler.properties[\"annealing_time_range\"][0]\n",
    "# print(f\"Minimum annealing time is: {min_anneal}\")\n",
    "max_slope = 1/0.5\n",
    "print(f\"The maximum slope for the annealing schedule can be: {max_slope}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d859a7f-57a1-4e8d-aad9-4d68c8469a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "J_coupls, J_matrix = def1DCouplings(L)\n",
    "runID = saveJ(J_coupls,L, dims=1)\n",
    "h = {}\n",
    "\n",
    "sampler_edgelist = sampler.edgelist\n",
    "embedding = find_embedding(J_coupls.keys(), sampler_edgelist)\n",
    "source = nx.Graph()\n",
    "source.add_edges_from(J_coupls.keys())\n",
    "target = sampler.to_networkx_graph()\n",
    "validEmbedding = verify_embedding(emb=embedding, source=source, target=target)\n",
    "embeddedSampler = FixedEmbeddingComposite(sampler, embedding)\n",
    "initStateSampled = embeddedSampler.sample_ising(h, J_coupls, num_reads=100)\n",
    "initRecord = initStateSampled.record\n",
    "\n",
    "energies = []\n",
    "for i in initRecord:\n",
    "    energies.append(i[1])\n",
    "\n",
    "energies = np.array(energies)\n",
    "values, counts = np.unique(energies, return_counts = 1)\n",
    "# print(values)\n",
    "# print(counts)\n",
    "print(initRecord)\n",
    "\n",
    "energy_occurrences = defaultdict(int)\n",
    "\n",
    "for _, energy, occurrences, _ in initRecord:\n",
    "    energy_occurrences[energy] += occurrences\n",
    "\n",
    "energies = []\n",
    "occurrences = []\n",
    "for energy, occurrence in sorted(energy_occurrences.items()):\n",
    "    energies.append(energy)\n",
    "    occurrences.append(occurrence)\n",
    "\n",
    "print(energies)\n",
    "print(occurrences)\n",
    "plt.scatter(energies, occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89753129-54be-48e2-a8c8-dc0fc5603326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(values)\n",
    "# print(counts)\n",
    "print(initRecord)\n",
    "\n",
    "energy_occurrences = defaultdict(int)\n",
    "\n",
    "for _, energy, occurrences, _ in initRecord:\n",
    "    energy_occurrences[energy] += occurrences\n",
    "\n",
    "energies = []\n",
    "occurrences = []\n",
    "for energy, occurrence in sorted(energy_occurrences.items()):\n",
    "    energies.append(energy)\n",
    "    occurrences.append(occurrence)\n",
    "\n",
    "print(energies)\n",
    "print(occurrences)\n",
    "plt.scatter(energies, occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb909e-46d2-41a2-907e-ca3ac7cd4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = zip(*reverse_schedule)\n",
    "fig, ax = plt.subplots(dpi = 300)\n",
    "ax.plot([0,100],[0,1], lw=10)\n",
    "# ax.plot(t,s, lw = 10)\n",
    "# plt.title(\"Reverse annealing schedule\")\n",
    "ax.set_xticks([0,50,100])\n",
    "ax.set_yticks([0,0.5,1.0])\n",
    "ax.set_xlabel(\"t [ns]\", fontsize = 24)\n",
    "ax.set_ylabel(\"s [1]\", fontsize = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812672e-c374-4b72-bf93-4899cc051c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 6\n",
    "J_coupls, J_matrix = def1DCouplings(L)\n",
    "runID = saveJ(J_coupls,L, dims=1)\n",
    "h = {}\n",
    "\n",
    "# Get initial state\n",
    "\n",
    "# sampler_edgelist = sampler.edgelist\n",
    "# embedding = find_embedding(J_coupls.keys(), sampler_edgelist)\n",
    "# source = nx.Graph()\n",
    "# source.add_edges_from(J_coupls.keys())\n",
    "# target = sampler.to_networkx_graph()\n",
    "# validEmbedding = verify_embedding(emb=embedding, source=source, target=target)\n",
    "# embeddedSampler = FixedEmbeddingComposite(sampler, embedding)\n",
    "# initStateSampled = embeddedSampler.sample_ising(h, J_coupls, num_reads=100)\n",
    "# initRecord = initStateSampled.record\n",
    "\n",
    "\n",
    "# initState = initStateSampled.first.sample\n",
    "# initState = flipRand(initState)\n",
    "\n",
    "# Define variables for standard annealing\n",
    "# sp_list = [0.1, 0.2, 0.278, 0.4, 0.5, 0.65, 0.7, 0.8, 0.9]\n",
    "# sp_list = [0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74]\n",
    "# sp_list = [0.66, 0.68, 0.70, 0.72, 0.74, 0.76]\n",
    "# sp_list = [0.64, 0.66, 0.68, 0.70]\n",
    "sp_list = [0.68]\n",
    "spectra = []\n",
    "energySpectrum = []\n",
    "\n",
    "for sp in sp_list:\n",
    "    tf = 100 # 100 microseconds schedule\n",
    "    # tp_end =  round(tf-(1.0-sp)/1.97,2) # Calculating near latest time available to quench\n",
    "    tp_end = optimizeEndpoint(tf, max_slope, sp)\n",
    "    pnq_schedule = [[0.0, 0.0], [2.0, sp], [tp_end, sp], [tf, 1.0]]\n",
    "    reverse_schedule = [[0.0, 1.0], [2.0, sp], [tp_end, sp], [tf, 1.0]]\n",
    "    numReads = 100\n",
    "    \n",
    "    # Do reverse annealing\n",
    "    revAnneal = embeddedSampler.sample_ising(h, J_coupls, \n",
    "                                             num_reads = numReads,\n",
    "                                             anneal_schedule = reverse_schedule,\n",
    "                                             initial_state = initState,\n",
    "                                             reinitialize_state = True)\n",
    "    record = revAnneal.record\n",
    "    \n",
    "    energies = []\n",
    "    for i in record:\n",
    "        energies.append(i[1])\n",
    "    \n",
    "    energies = np.array(energies)\n",
    "\n",
    "    # print(f\"--------------- Reverse annealing results - sp = {sp} ---------------\")\n",
    "    values, counts = np.unique(energies, return_counts = 1)\n",
    "    # f.write(values)\n",
    "    if(len(energySpectrum)<len(values)):\n",
    "        energySpectrum = values.copy()\n",
    "    # print(values)\n",
    "    # f.write(counts)\n",
    "    # print(counts)\n",
    "    spectrum = [values, counts]\n",
    "    spectra.append(spectrum)\n",
    "\n",
    "markers = ['o', 's', '^', 'D', 'v', '>', '<', 'P', 'X']\n",
    "colours = ['blue','orange','green','red','purple','brown','pink','cyan','magenta']\n",
    "# print(f\"The total list of sampled energies are:\\n{energySpectrum}\")\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(dpi = 300)\n",
    "for i in range(len(spectra)):\n",
    "    values = spectra[i][0] \n",
    "    counts = spectra[i][1]\n",
    "    plt.scatter(values, counts, label = f\"sp = {sp_list[i]}\", marker=markers[i], facecolors='none', edgecolors=colours[i])\n",
    "    plt.plot(values, counts, linestyle=':', color=colours[i])\n",
    "# ax.set_title(f\"Sampled energy spectra with varying sp - {numReads} readings per run\")\n",
    "ax.set_title(f\"Sampled energy spectra - {numReads} readings\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_xlabel(\"Energies\")\n",
    "plt.legend()\n",
    "figPath = notebookOutputsPth +\"/Spectrum_\"+ runID +\".png\"\n",
    "plt.savefig(figPath)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e33236-e977-4b17-aae1-aca5a6767b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(energySpectrum)\n",
    "for i in range(len(spectra)):\n",
    "    print(f\"sp = {sp_list[i]}: spectrum - ({spectra[i][0]} {spectra[i][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c79cc-8b00-477e-83d6-d99d5cba94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5\n",
    "J_coupls, J_matrix = def1DCouplings(L)\n",
    "saveJ(J_coupls,L, dims=1)\n",
    "h = {}\n",
    "\n",
    "sampler_edgelist = sampler.edgelist\n",
    "embedding = find_embedding(J_coupls.keys(), sampler_edgelist)\n",
    "source = nx.Graph()\n",
    "source.add_edges_from(J_coupls.keys())\n",
    "target = sampler.to_networkx_graph()\n",
    "validEmbedding = verify_embedding(emb=embedding, source=source, target=target)\n",
    "embeddedSampler = FixedEmbeddingComposite(sampler, embedding)\n",
    "initStateSampled = embeddedSampler.sample_ising(h, J_coupls, num_reads=100)\n",
    "\n",
    "initState = initStateSampled.first.sample\n",
    "initState = initStateSampled.record[0][\"sample\"]\n",
    "initState = initStateSampled.first.sample\n",
    "initState = flipRand(initState)\n",
    "\n",
    "sp = 0.278\n",
    "tf = 100 # 100 microseconds schedule\n",
    "# tp_end =  round(tf-(1.0-sp)/1.97,2) # Calculating near latest time available to quench\n",
    "tp_end = optimizeEndpoint(tf, maxSlope, sp)\n",
    "pnq_schedule = [[0.0, 0.0], [2.0, sp], [tp_end, sp], [tf, 1.0]]\n",
    "reverse_schedule = [[0.0, 1.0], [2.0, sp], [tp_end, sp], [tf, 1.0]]\n",
    "numReads=1000\n",
    "\n",
    "revAnneal = embeddedSampler.sample_ising(h, J_coupls, \n",
    "                                         num_reads = numReads,\n",
    "                                         anneal_schedule = reverse_schedule,\n",
    "                                         initial_state = initState,\n",
    "                                         reinitialize_state = True)\n",
    "record = revAnneal.record\n",
    "\n",
    "energies = []\n",
    "for i in record:\n",
    "    energies.append(i[1])\n",
    "\n",
    "energies = np.array(energies)\n",
    "\n",
    "print(\"Reverse annealing results\")\n",
    "values, counts = np.unique(energies, return_counts = 1)\n",
    "print(values)\n",
    "print(counts)\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(values, counts)\n",
    "plt.title(f\"Energy occurances - A state read {numReads} times - Reverse Annealing\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Energy sampled\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ----------------- Standard Annealing run for comparision ------------------------------------------------------\n",
    "stdAnneal = embeddedSampler.sample_ising(h, J_coupls,\n",
    "                                         num_reads = 1000)\n",
    "tempNrgs = []\n",
    "tempCounts = []\n",
    "for i in stdAnneal.record:\n",
    "    tempNrgs.append(i[1])\n",
    "    tempCounts.append(i[2])\n",
    "\n",
    "stdNrgs = []\n",
    "stdCounts = []\n",
    "\n",
    "for i in range(len(tempCounts)):\n",
    "    # print(f\"\\n{i}\")\n",
    "    if tempNrgs[i] not in stdNrgs:\n",
    "        stdNrgs.append(tempNrgs[i])\n",
    "        # print(f\"Appending energy: {tempNrgs[i]}\")\n",
    "        stdCounts.append(tempCounts[i])\n",
    "        # print(f\"Appending count: {tempCounts[i]}\")\n",
    "    else:\n",
    "        stdCounts[-1] += tempCounts[i]\n",
    "    #     print(f\"Adding count: {tempCounts[i]}\")\n",
    "    # print(f\"stdNrgs: {stdNrgs}\")\n",
    "    # print(f\"stdCounts: {stdCounts}\")\n",
    "\n",
    "print(\"Standard annealing results\")\n",
    "print(stdNrgs)\n",
    "print(stdCounts)\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(stdNrgs, stdCounts)\n",
    "plt.title(f\"Energy occurances - A state read {numReads} times - Standard Annealing\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Energy sampled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220bad33-0706-4b4d-90ea-9ea0bfd205dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stdAnneal.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7a69a-55f7-486e-b425-e51448e4e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1-D, No PBC \n",
    "What happens in this cell:\n",
    "Defing matrix length, generate couplings, send job to Samplers, \n",
    "print out ground state energy sampled, print out ground state energy calculated, print validation result\n",
    "\"\"\"\n",
    "L = 4\n",
    "\n",
    "# print(J)\n",
    "nrgs = []\n",
    "\n",
    "h = {}\n",
    "\n",
    "# for i in range(1):\n",
    "J_couplings, J_matrix = def1DCouplings(L)\n",
    "saveJ(J_couplings,L, dims = 1)\n",
    "stdAnneal = embeddedSampler.sample_ising(h, J_coupls, \n",
    "                                         num_reads = 1000)\n",
    "\n",
    "\n",
    "ground_state = {s_i:-1 for s_i in range(16)}\n",
    "print(f\"Sampled energy reading {i}:\")\n",
    "print(\"\\t\" + str(sampleset.first.energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3a102-049e-4a5b-a022-9883d7f90043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little blurb to manually check that \n",
    "stateInd = 4\n",
    "print(dictToArr(sampleset.samples()[0]))\n",
    "print(numToState(degenerateStates[stateInd],L*L))\n",
    "print(np.all(dictToArr(sampleset.samples()[0]) == numToState(degenerateStates[4],L*L)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3d44b-b994-432d-9311-8d558895a602",
   "metadata": {},
   "source": [
    "For next time, fix the seperator, get that spin glass server file working; implement the annealing schedule and look at the values sampled, should be showing some signs of super position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
